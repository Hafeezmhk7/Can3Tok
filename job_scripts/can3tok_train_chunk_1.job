#!/bin/bash
#SBATCH --job-name=can3tok_semantic
#SBATCH --partition=gpu_h100
#SBATCH --gpus=1
#SBATCH --time=08:00:00
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --mem=64G
#SBATCH --output=logs/can3tok_semantic_%j.out
#SBATCH --error=logs/can3tok_semantic_%j.err

echo "=========================================="
echo "Can3Tok Training - SEMANTIC LOSS"
echo "=========================================="
echo "Job ID: $SLURM_JOB_ID"
echo "Start time: $(date)"
echo ""
echo "Version: FIXED VALIDATION + SEMANTIC LOSS"
echo "Semantic supervision for improved latent space"
echo ""

# Configuration
export WANDB_API_KEY="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"

USE_WANDB=False
BATCH_SIZE=100
NUM_EPOCHS=1000
LEARNING_RATE=1e-5
KL_WEIGHT=1e-5

TRAIN_SCENES=600
VAL_SCENES=50

SAMPLING_METHOD="opacity"  # opacity or random

# ============================================================================
# NEW: Semantic Loss Configuration
# ============================================================================
SEGMENT_WEIGHT=0.1      # β - Weight for segment contrastive loss
INSTANCE_WEIGHT=0.0     # γ - Weight for instance contrastive loss
SEMANTIC_TEMP=0.07      # τ - Temperature parameter
SEMANTIC_SUBSAMPLE=2000 # Subsample size for memory efficiency

EVAL_EVERY=20
FAILURE_THRESHOLD=1000

WANDB_ENTITY="3D-SSC"
WANDB_PROJECT="Can3Tok-Semantic"

echo "Configuration:"
echo "  Batch size: $BATCH_SIZE"
echo "  Epochs: $NUM_EPOCHS"
echo "  Train scenes: $TRAIN_SCENES"
echo "  Val scenes: $VAL_SCENES"
echo "  Sampling: $SAMPLING_METHOD"
echo ""
echo "Semantic Loss:"
echo "  Segment weight (β): $SEGMENT_WEIGHT"
echo "  Instance weight (γ): $INSTANCE_WEIGHT"
echo "  Temperature (τ): $SEMANTIC_TEMP"
echo "  Subsample: $SEMANTIC_SUBSAMPLE"
echo ""
echo "Expected Results:"
echo "  - Semantic loss: ~0.5 → ~0.2 over training"
echo "  - Val L2 improvement: 5-15% over baseline"
echo "  - Both recon and semantic should decrease"
echo ""

# Setup
module purge && module load 2023 && module load CUDA/12.1.1
export PATH="/home/yli11/.conda/envs/can3tok/bin:$PATH"
export LD_LIBRARY_PATH="/home/yli11/.conda/envs/can3tok/lib/python3.11/site-packages/torch/lib:$LD_LIBRARY_PATH"
cd /home/yli11/scratch/Hafeez_thesis/Can3Tok
mkdir -p logs checkpoints

if [ "$USE_WANDB" = "True" ]; then
    wandb login $WANDB_API_KEY --relogin 2>/dev/null
    echo "✓ W&B enabled"
else
    echo "✗ W&B disabled"
fi

echo ""
echo "Starting training with semantic loss..."
echo ""

# Build training command
TRAIN_CMD="python gs_can3tok_2.py"
TRAIN_CMD="$TRAIN_CMD --batch_size $BATCH_SIZE"
TRAIN_CMD="$TRAIN_CMD --num_epochs $NUM_EPOCHS"
TRAIN_CMD="$TRAIN_CMD --lr $LEARNING_RATE"
TRAIN_CMD="$TRAIN_CMD --kl_weight $KL_WEIGHT"
TRAIN_CMD="$TRAIN_CMD --eval_every $EVAL_EVERY"
TRAIN_CMD="$TRAIN_CMD --failure_threshold $FAILURE_THRESHOLD"
TRAIN_CMD="$TRAIN_CMD --train_scenes $TRAIN_SCENES"
TRAIN_CMD="$TRAIN_CMD --val_scenes $VAL_SCENES"
TRAIN_CMD="$TRAIN_CMD --sampling_method $SAMPLING_METHOD"

# Add semantic loss parameters
TRAIN_CMD="$TRAIN_CMD --segment_loss_weight $SEGMENT_WEIGHT"
TRAIN_CMD="$TRAIN_CMD --instance_loss_weight $INSTANCE_WEIGHT"
TRAIN_CMD="$TRAIN_CMD --semantic_temperature $SEMANTIC_TEMP"
TRAIN_CMD="$TRAIN_CMD --semantic_subsample $SEMANTIC_SUBSAMPLE"

# Add W&B if enabled
if [ "$USE_WANDB" = "True" ]; then
    TRAIN_CMD="$TRAIN_CMD --use_wandb"
    TRAIN_CMD="$TRAIN_CMD --wandb_project $WANDB_PROJECT"
    TRAIN_CMD="$TRAIN_CMD --wandb_entity $WANDB_ENTITY"
fi

echo "Command: $TRAIN_CMD"
echo ""

eval $TRAIN_CMD
TRAIN_EXIT=$?

# Results
echo ""
echo "=========================================="
if [ $TRAIN_EXIT -eq 0 ]; then
    echo "✓ Training Completed!"
    echo "=========================================="
    echo ""
    echo "Duration: $SECONDS seconds"
    if [ "$USE_WANDB" = "True" ]; then
        echo "W&B: https://wandb.ai/$WANDB_ENTITY/$WANDB_PROJECT"
    fi
    echo ""
    echo "Results to check:"
    echo "  1. Semantic loss decreasing over epochs"
    echo "  2. Reconstruction loss still decreasing"
    echo "  3. Val L2 error improved vs baseline"
    echo "  4. Train-val gap reasonable (<50%)"
    echo ""
else
    echo "✗ Training Failed (exit: $TRAIN_EXIT)"
fi

echo "End time: $(date)"
echo "=========================================="
